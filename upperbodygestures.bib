@inproceedings{AlAgha2010,
address = {New York, New York, USA},
author = {AlAgha, Iyad and Hatch, Andrew and Ma, Linxiao and Burd, Elizabeth},
booktitle = {ACM International Conference on Interactive Tabletops and Surfaces - ITS '10},
doi = {10.1145/1936652.1936688},
file = {:C$\backslash$:/Users/d6ammt/Documents/Mendeley Desktop//AlAgha et al. - 2010 - Towards a teacher-centric approach for multi-touch surfaces in classrooms.pdf:pdf},
isbn = {9781450303996},
keywords = {classroom,multi-touch tabletop,remote access},
month = nov,
pages = {187},
publisher = {ACM Press},
title = {{Towards a teacher-centric approach for multi-touch surfaces in classrooms}},
url = {http://dl.acm.org/citation.cfm?id=1936652.1936688},
year = {2010}
}
@article{Apple1990,
abstract = {Given the increasing power of conservative movements in the larger society, there is considerable pressure currently not only to redefine the manner in which education is carried out, but to redefine what education is actually for This has had a major impact on teachers' autonomy and the definition of what counts as a skill. We argue that teaching is a specific kind of labor process, one that is currently being subject to rationalization, deskilling and intensification. Since teaching has historically been seen as largely "women's paid work," the gender implications of such tendencies are crucial. By interpreting teaching in gender and labor process terms, we report data from an ethnographic study of the use of a computer literacy curriculum to illuminate the effects of these tendencies on teachers' daily lives. In this context, teachers often employed a prepackaged curriculum that deskilled them and frequently left them bored and reliant on outside experts and purchased material. Yet they also employed the curriculum for their own purposes, using it to partly solve the problems caused by their intense schedule and work load. This pragmatic response cannot be understood unless the gendered realities of teachers' work inside and outside of the school are recognized.},
author = {Apple, M. W. and Jungck, S.},
doi = {10.3102/00028312027002227},
file = {:C$\backslash$:/Users/d6ammt/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Apple, Jungck - 1990 - You Don't Have to Be a Teacher to Teach This Unit Teaching, Technology, and Gender in the Classroom.pdf:pdf},
issn = {0002-8312},
journal = {American Educational Research Journal},
month = jan,
number = {2},
pages = {227--251},
title = {{"You Don't Have to Be a Teacher to Teach This Unit:" Teaching, Technology, and Gender in the Classroom}},
url = {http://aer.sagepub.com/cgi/content/abstract/27/2/227},
volume = {27},
year = {1990}
}
@misc{Avin2011,
	author = {{Avin}},
	title = {{SensorKinect}},
	howpublished  = {https://github.com/avin2/SensorKinect},
	note = {[Online; accessed 23-August-2012]},
	urldate = {23/08/12},
	year = {2011}
}
@inproceedings{Bellmore2011,
abstract = {This paper introduces an interactive display system guided by a human observer's gesture, facial pose, and facial expression. The Kinect depth sensor is used to detect and track an observer's skeletal joints while the RGB camera is used for detailed facial analysis. The display consists of active regions that the observer can manipulate with body gestures and secluded regions that are activated through head pose and facial expression. The observer receives realtime feedback allowing for intuitive navigation of the interface. A storefront interactive display was created and feedback was collected from over one hundred subjects. Promising results demonstrate the potential of the proposed approach for human-computer interaction applications.},
author = {Bellmore, Colin and Ptucha, Raymond and Savakis, Andreas},
booktitle = {2011 Western New York Image Processing Workshop},
doi = {10.1109/WNYIPW.2011.6122883},
file = {:C$\backslash$:/Users/d6ammt/Documents/Mendeley Desktop//Bellmore, Ptucha, Savakis - 2011 - Interactive display using depth and RGB sensors for face and gesture control.pdf:pdf},
isbn = {978-1-4673-0419-1},
month = nov,
pages = {1--4},
publisher = {IEEE},
title = {{Interactive display using depth and RGB sensors for face and gesture control}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=6122883},
year = {2011}
}
@inproceedings{Caon2011,
address = {Barcelona, Spain},
author = {Caon, M and Yue, Y and Tscherrig, J},
booktitle = {2011 Ambient 1st International Conference on Ambient Computing, Applications, Services and Technologies},
file = {:C$\backslash$:/Users/d6ammt/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Caon, Yue, Tscherrig - 2011 - Context-Aware 3D Gesture Interaction Based on Multiple Kinects.pdf:pdf},
pages = {7--12},
publisher = {IARIA},
title = {{Context-Aware 3D Gesture Interaction Based on Multiple Kinects}},
url = {http://www.thinkmind.org/index.php?view=article\&articleid=ambient\_2011\_1\_20\_60044},
year = {2011}
}
@article{Chen2005,
abstract = {In the context of distributed collaborative learning, the teacher's role is different from traditional teacher-centered environments, they are coordinators/facilitators, guides, and co-learners. They monitor the collaboration activities within a group, detect problems and intervene in the collaboration to give advice and learn alongside students at the same time. We have designed an Assistant to support teachers' intervention in collaborative knowledge building. The Assistant monitors the collaboration, visualizes it and provides advice to the teacher on the subject domain and the collaboration process. The goal of the research present in this paper is to explore the possibilities of enriching Computer Supported Collaborative Learning (CSCL) environments with tools to support collaborative interaction.},
author = {Chen, Weiqin},
doi = {10.1016/j.jnca.2005.01.001},
file = {:C$\backslash$:/Users/d6ammt/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen - 2005 - Supporting teachers' intervention in collaborative knowledge building.pdf:pdf},
issn = {10848045},
journal = {Journal of Network and Computer Applications},
keywords = {cscl,knowledge building,software agents},
month = aug,
number = {2-3},
pages = {200--215},
title = {{Supporting teachers' intervention in collaborative knowledge building}},
url = {http://dx.doi.org/10.1016/j.jnca.2005.01.001},
volume = {29},
year = {2005}
}
@book{Davison2012,
author = {Davison, A},
publisher = {McGraw-Hill Prof Med/Tech},
title = {{Kinect Open Source Programming Secrets: Hacking the Kinect With Openni, Nite, and Java}},
url = {http://scholar.google.co.uk/scholar?hl=en\&q=+Kinect+Open+Source+Programming+Secrets\&btnG=\&as\_sdt=1,5\&as\_sdtp=\#0},
year = {2012}
}
@inproceedings{Dubois2011,
abstract = {This work is related to the development of a marker less system allowing the tracking of elderly people at home. Microsoft Kinect is a low cost 3D camera adapted to the tracking of human movements. We propose a method for making the fusion of the information provided by several Kinects. The observed space is tesselated into cells forming a 3D occupancy grid. We calculate a probability of occupation for each cell of the grid. From this probability we distinguish whether the cells are occupied or not by a static object (wall) or a mobile object (chair, human being). This categorization is realized in real-time using a simple three states HMM. The proposed method for discriminating between mobile and static objects in a room is the main contribution of this paper. The use of HMMs allows to deal with an aliasing problem since mobile objects result in the same observation as static objects. The approach is evaluated in simulation and in a real environment showing an efficient real-time discrimination between cells occupied by mobile objects and cells occupied by static objects.},
author = {Dubois, Amandine and Dib, Abdallah and Charpillet, Francois},
booktitle = {2011 IEEE 23rd International Conference on Tools with Artificial Intelligence},
doi = {10.1109/ICTAI.2011.188},
file = {:C$\backslash$:/Users/d6ammt/Documents/Mendeley Desktop//Dubois, Dib, Charpillet - 2011 - Using HMMs for Discriminating Mobile from Static Objects in a 3D Occupancy Grid.pdf:pdf},
isbn = {978-1-4577-2068-0},
month = nov,
pages = {170--176},
publisher = {IEEE},
title = {{Using HMMs for Discriminating Mobile from Static Objects in a 3D Occupancy Grid}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=6103323},
year = {2011}
}
@article{Goth2011,
author = {Goth, Gregory},
doi = {10.1145/2043174.2043181},
file = {:C$\backslash$:/Users/d6ammt/Documents/Mendeley Desktop//Goth - 2011 - Brave NUI world.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = dec,
number = {12},
pages = {14},
title = {{Brave NUI world}},
url = {http://dl.acm.org/ft\_gateway.cfm?id=2043181\&type=html},
volume = {54},
year = {2011}
}
@inproceedings{HatchA.HigginsS&Mercier2009,
address = {Garmisch-Partenkirchen},
author = {Hatch, A. and Higgins, S. and Mercier, E.},
booktitle = {STELLAR Alpine Rendez-Vous Workshop 2009: Tabletops for Education and Training},
title = {{SynergyNet: Supporting Collaborative Learning in an Immersive Environment}},
year = {2009}
}
@article{Hall1968,
abstract = {The effects of contingent teacher attention on study behavior were investigated. Individual rates of study were recorded for one first-grade and five third-grade pupils who had high rates of disruptive or dawdling behavior. A reinforcement period (in which teacher attention followed study behavior and non-study behaviors were ignored) resulted in sharply increased study rates. A brief reversal of the contingency (attention occurred only after periods of non-study behavior) again produced low rates of study. Reinstatement of teacher attention as reinforcement for study once again markedly increased study behavior. Follow-up observations indicated that the higher study rates were maintained after the formal program terminated.},
author = {Hall, R V and Lund, D and Jackson, D},
file = {:C$\backslash$:/Users/d6ammt/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hall, Lund, Jackson - 1968 - Effects of teacher attention on study behavior.pdf:pdf},
issn = {0021-8855},
journal = {Journal of applied behavior analysis},
month = jan,
number = {1},
pages = {1--12},
pmid = {16795155},
title = {{Effects of teacher attention on study behavior.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1310970\&tool=pmcentrez\&rendertype=abstract},
volume = {1},
year = {1968}
}
@article{Hatch2011,
author = {Hatch, A and Higgins, S},
journal = {Proceedings of CSCL 2011},
title = {{NumberNet: Using multi-touch technology to support within and between-group mathematics learning}},
url = {http://scholar.google.co.uk/scholar?q=NumberNet\&btnG=\&hl=en\&as\_sdt=0,5\#1},
year = {2011}
}
@misc{Hazelcast2009, 
author = {{Hazelcast Software}},
title = {{Hazelcast}},
howpublished = {http://www.hazelcast.com/},
note = {[Online; accessed 23-August-2012]},
urldate = {23/08/12},
year = {2009}
}
@article{Kainz2012,
author = {Kainz, B and Hauswiesner, S and Reitmayr, G},
file = {:C$\backslash$:/Users/d6ammt/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kainz, Hauswiesner, Reitmayr - 2012 - OmniKinect Real-Time Dense Volumetric Data Acquisition and Applications.pdf:pdf},
title = {{OmniKinect: Real-Time Dense Volumetric Data Acquisition and Applications}},
url = {http://www.technotecture.com/system/files/publication/final\_VRST12\_Kainz\_etal.pdf},
year = {2012}
}
@inproceedings{Kaltenbrunner2009,
address = {New York, New York, USA},
author = {Kaltenbrunner, Martin},
booktitle = {Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces - ITS '09},
doi = {10.1145/1731903.1731906},
file = {:C$\backslash$:/Users/d6ammt/Documents/Mendeley Desktop//Kaltenbrunner - 2009 - reacTIVision and TUIO.pdf:pdf},
isbn = {9781605587332},
keywords = {computer vision,human computer interaction,interactive surfaces,protocols,tangible user interfaces},
month = nov,
pages = {9},
publisher = {ACM Press},
title = {{reacTIVision and TUIO}},
url = {http://dl.acm.org/citation.cfm?id=1731903.1731906},
year = {2009}
}
@article{Karabenick2011,
abstract = {Contributions to this special section represent advances in understanding help seeking as a self-regulated learning strategy that occurs in classrooms, during computer-mediated communications, and when using intelligent systems that provide help to improve learners’ help-seeking skills and knowledge acquisition. Collectively, the research and development contributes information relevant for all phases of the help-seeking process. My comments focus on: (a) features of technology-supported help seeking that have implications for motivation, (b) the need for increased attention to the instructional context in which technology-supported help seeking occurs, (c) a necessary convergence of classroom and technology-supported help-seeking research paradigms, and (d) reconsideration of help seeking as a social-interactive strategy.},
author = {Karabenick, Stuart A.},
doi = {10.1016/j.learninstruc.2010.07.007},
file = {:C$\backslash$:/Users/d6ammt/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Karabenick - 2011 - Classroom and technology-supported help seeking The need for converging research paradigms.pdf:pdf},
issn = {09594752},
journal = {Learning and Instruction},
keywords = {classroom context,help-seeking,information and communication technology (ict),motivation,social interaction},
month = apr,
number = {2},
pages = {290--296},
title = {{Classroom and technology-supported help seeking: The need for converging research paradigms}},
url = {http://dx.doi.org/10.1016/j.learninstruc.2010.07.007},
volume = {21},
year = {2011}
}
@book{Kean2011,
author = {Kean, S and Hall, JC and Perry, P},
booktitle = {Meet the Kinect},
title = {{Meet the Kinect: An Introduction to Programming Natural User Interfaces}},
url = {http://www.springerlink.com/index/XV667J038KGG707T.pdf},
year = {2011}
}
@inproceedings{Kim2008,
address = {Anchorage},
author = {Kim, Young Min and Chan, Derek and Theobalt, Christian and Thrun, Sebastian},
booktitle = {IEEE CVPR},
file = {:C$\backslash$:/Users/d6ammt/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Young Min Kim - Unknown - Design and Calibration of a Multi-view TOF Sensor Fusion System.pdf:pdf},
pages = {1524--1530},
title = {{Design and Calibration of a Multi-view TOF Sensor Fusion System}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.178.202},
year = {2008}
}
@misc{kramer2011,
	author = {Kramer, C. E. and Underkoffler, J. and Norris, M. A. D. L. and Brown, M. and Kung, D. and Armstrong, S.},
	title = {{Mezzanine}},
	howpublished  = {http://oblong.com/what-we-do/mezzanine},
	note = {[Online; accessed 05-March-2013]},
	urldate = {16/11/12},
	year = {2011}
}
@book{Kramer2012,
author = {Kramer, J and Parker, M and Herrera, D},
title = {{Hacking the Kinect}},
url = {http://books.google.co.uk/books?hl=en\&lr=\&id=IftkzqRjbO4C\&oi=fnd\&pg=PP1\&dq=hacking+the+kinect\&ots=XuVzXafrB4\&sig=eMm8mYon66DeH3-JTq1sjAj3ZDU},
year = {2012}
}
@inproceedings{Lai2012,
abstract = {Automatic recognition of human actions from video has been studied for many years. Although still very difficult in uncontrolled scenarios, it has been successful in more restricted settings (e.g., fixed viewpoint, no occlusions) with recognition rates approaching 100\%. However, the best-performing methods are complex and computationally-demanding and thus not well-suited for real-time deployments. This paper proposes to leverage the Kinect camera for close-range gesture recognition using two methods. Both methods use feature vectors that are derived from the skeleton model provided by the Kinect SDK in real-time. Although both methods perform nearest-neighbor classification, one method does this in the space of features using the Euclidean distance metric, while the other method does this in the space of feature covariances using a log-Euclidean metric. Both methods recognize 8 hand gestures in real time achieving correct-classification rates of over 99\% on a dataset of 20 subjects but the method based on Euclidean distance requires feature-vector collections to be of the same size, is sensitive to temporal misalignment, and has higher computation and storage requirements.},
author = {Lai, Kam and Konrad, Janusz and Ishwar, Prakash},
booktitle = {2012 IEEE Southwest Symposium on Image Analysis and Interpretation},
month = apr,
pages = {185--188},
publisher = {IEEE},
title = {{A gesture-driven computer interface using Kinect}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6202484},
year = {2012}
}
@article{Leyvand2011,
abstract = {Kinect Identity, a key component of Microsoft's Kinect for the Xbox 360, combines multiple technologies and careful user interaction design to achieve the goal of recognizing and tracking player identity.},
author = {Leyvand, Tommer and Meekhof, Casey and Wei, Yi-Chen and Sun, Jian and Guo, Baining},
doi = {10.1109/MC.2011.114},
file = {:C$\backslash$:/Users/d6ammt/Documents/Mendeley Desktop//Leyvand et al. - 2011 - Kinect Identity Technology and Experience.pdf:pdf},
issn = {0018-9162},
journal = {Computer},
month = apr,
number = {4},
pages = {94--96},
title = {{Kinect Identity: Technology and Experience}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5742015},
volume = {44},
year = {2011}
}
@article{Lloyd2011,
author = {Lloyd, S. A. and Robertson, C. L.},
issn = {0098-6283},
journal = {Teaching of Psychology},
language = {en},
month = dec,
number = {1},
pages = {67--71},
publisher = {SAGE Publications},
title = {{Screencast Tutorials Enhance Student Learning of Statistics}},
url = {http://top.sagepub.com/content/39/1/67.full},
volume = {39},
year = {2011}
}
@inproceedings{Luber2011,
abstract = {People tracking is a key component for robots that are deployed in populated environments. Previous works have used cameras and 2D and 3D range finders for this task. In this paper, we present a 3D people detection and tracking approach using RGB-D data. We combine a novel multi-cue person detector for RGB-D data with an on-line detector that learns individual target models. The two detectors are integrated into a decisional framework with a multi-hypothesis tracker that controls on-line learning through a track interpretation feedback. For on-line learning, we take a boosting approach using three types of RGB-D features and a confidence maximization search in 3D space. The approach is general in that it neither relies on background learning nor a ground plane assumption. For the evaluation, we collect data in a populated indoor environment using a setup of three Microsoft Kinect sensors with a joint field of view. The results demonstrate reliable 3D tracking of people in RGB-D data and show how the framework is able to avoid drift of the on-line detector and increase the overall tracking performance.},
author = {Luber, Matthias and Spinello, Luciano and Arras, Kai O.},
booktitle = {2011 IEEE/RSJ International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2011.6095075},
file = {:C$\backslash$:/Users/d6ammt/Documents/Mendeley Desktop//Luber, Spinello, Arras - 2011 - People tracking in RGB-D data with on-line boosted target models.pdf:pdf},
isbn = {978-1-61284-456-5},
month = sep,
pages = {3844--3849},
publisher = {IEEE},
title = {{People tracking in RGB-D data with on-line boosted target models}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=6095075},
year = {2011}
}
@inproceedings{Maimone2011,
abstract = {This paper introduces a proof-of-concept telepresence system that offers fully dynamic, real-time 3D scene capture and continuous-viewpoint, head-tracked stereo 3D display without requiring the user to wear any tracking or viewing apparatus. We present a complete software and hardware framework for implementing the system, which is based on an array of commodity Microsoft Kinect™color-plus-depth cameras. Novel contributions include an algorithm for merging data between multiple depth cameras and techniques for automatic color calibration and preserving stereo quality even with low rendering rates. Also presented is a solution to the problem of interference that occurs between Kinect cameras with overlapping views. Emphasis is placed on a fully GPU-accelerated data processing and rendering pipeline that can apply hole filling, smoothing, data merger, surface generation, and color correction at rates of up to 100 million triangles/sec on a single PC and graphics board. Also presented is a Kinect-based markerless tracking system that combines 2D eye recognition with depth information to allow head-tracked stereo views to be rendered for a parallax barrier autostereoscopic display. Our system is affordable and reproducible, offering the opportunity to easily deliver 3D telepresence beyond the researcher's lab.},
author = {Maimone, Andrew and Fuchs, Henry},
booktitle = {2011 10th IEEE International Symposium on Mixed and Augmented Reality},
doi = {10.1109/ISMAR.2011.6092379},
file = {:C$\backslash$:/Users/d6ammt/Documents/Mendeley Desktop//Maimone, Fuchs - 2011 - Encumbrance-free telepresence system with real-time 3D capture and display using commodity depth cameras.pdf:pdf},
isbn = {978-1-4577-2185-4},
month = oct,
pages = {137--146},
publisher = {IEEE},
title = {{Encumbrance-free telepresence system with real-time 3D capture and display using commodity depth cameras}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=6092379},
year = {2011}
}
@inproceedings{Maimone2012,
abstract = {We present a method for reducing interference between multiple structured light-based depth sensors operating in the same spectrum with rigidly attached projectors and cameras. A small amount of motion is applied to a subset of the sensors so that each unit sees its own projected pattern sharply, but sees a blurred version of the patterns of other units. If high spacial frequency patterns are used, each sensor sees its own pattern with higher contrast than the patterns of other units, resulting in simplified pattern disambiguation. An analysis of this method is presented for a group of commodity Microsoft Kinect color-plus-depth sensors with overlapping views. We demonstrate that applying a small vibration with a simple motor to a subset of the Kinect sensors results in reduced interference, as manifested as holes and noise in the depth maps. Using an array of six Kinects, our system reduced interference-related missing data from from 16.6\% to 1.4\% of the total pixels. Another experiment with three Kinects showed an 82.2\% percent reduction in the measurement error introduced by interference. A side-effect is blurring in the color images of the moving units, which is mitigated with post-processing. We believe our technique will allow inexpensive commodity depth sensors to form the basis of dense large-scale capture systems.},
author = {Maimone, Andrew and Fuchs, Henry},
booktitle = {2012 IEEE Virtual Reality (VR)},
doi = {10.1109/VR.2012.6180879},
file = {:C$\backslash$:/Users/d6ammt/Documents/Mendeley Desktop/Maimone, Fuchs - 2012 - Reducing interference between multiple structured light depth sensors using motion.pdf:pdf},
isbn = {978-1-4673-1246-2},
month = mar,
pages = {51--54},
publisher = {IEEE},
title = {{Reducing interference between multiple structured light depth sensors using motion}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6180879},
year = {2012}
}
@inproceedings{Matsushita1997,
address = {New York, New York, USA},
author = {Matsushita, Nobuyuki and Rekimoto, Jun},
booktitle = {Proceedings of the 10th annual ACM symposium on User interface software and technology - UIST '97},
doi = {10.1145/263407.263549},
file = {:C$\backslash$:/Users/d6ammt/Documents/Mendeley Desktop//Matsushita, Rekimoto - 1997 - HoloWall.pdf:pdf},
isbn = {0897918819},
keywords = {augmented reality,infrared,ubiquitous computing,wall interfaces},
month = oct,
pages = {209--210},
publisher = {ACM Press},
title = {{HoloWall}},
url = {http://dl.acm.org/citation.cfm?id=263407.263549},
year = {1997}
}
@unpublished{McNaughton2013a,
	author = {McNaughton, James and Mercier, Emma and Smith, Shamus P. and Burd, Elizabeth},
	title = {{Controlling Classroom Technology with Upper-Body Gestures}},
	note = {{Submitted}},
	month = may,
	year = {2013}
}
@article{Selwyn2011,
author = {Selwyn, N},
title = {{Education and technology: key issues and debates}},
url = {http://books.google.co.uk/books?hl=en\&amp;lr=\&amp;id=SFYeie9rPdsC\&amp;oi=fnd\&amp;pg=PP2\&amp;ots=yK5yQ7gXSr\&amp;sig=opvPiIxCXMGBtCg32QdylDljCK8},
year = {2011}
}
@inproceedings{Mehrotra2011,
abstract = {Depth cameras are gaining interest rapidly in the market as depth plus RGB is being used for a variety of applications ranging from foreground/background segmentation, face tracking, activity detection, and free viewpoint video rendering. In this paper, we present a low-complexity, near-lossless codec for coding depth maps. This coding requires no buffering of video frames, is table-less, can encode or decode a frame in close to 5ms with little code optimization, and provides between 7:1 to 16:1 compression ratio for near-lossless coding of 16-bit depth maps generated by the Kinect camera.},
author = {Mehrotra, Sanjeev and Zhang, Zhengyou and Cai, Qin and Zhang, Cha and Chou, Philip A.},
booktitle = {2011 IEEE 13th International Workshop on Multimedia Signal Processing},
doi = {10.1109/MMSP.2011.6093803},
file = {:C$\backslash$:/Users/d6ammt/Documents/Mendeley Desktop//Mehrotra et al. - 2011 - Low-complexity, near-lossless coding of depth maps from kinect-like depth cameras.pdf:pdf},
isbn = {978-1-4577-1434-4},
month = oct,
pages = {1--6},
publisher = {IEEE},
title = {{Low-complexity, near-lossless coding of depth maps from kinect-like depth cameras}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=6093803},
year = {2011}
}
@inproceedings{Meng2012,
address = {New York, New York, USA},
author = {Meng, Rufeng and Isenhower, Jason and Qin, Chuan and Nelakuditi, Srihari},
booktitle = {Proceedings of the thirteenth ACM international symposium on Mobile Ad Hoc Networking and Computing - MobiHoc '12},
doi = {10.1145/2248371.2248417},
file = {:C$\backslash$:/Users/d6ammt/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Meng et al. - 2012 - Can smartphone sensors enhance kinect experience.pdf:pdf},
isbn = {9781450312813},
keywords = {games,kinect,sensor fusion,smartphone},
month = jun,
pages = {265},
publisher = {ACM Press},
title = {{Can smartphone sensors enhance kinect experience?}},
url = {http://dl.acm.org/citation.cfm?id=2248371.2248417},
year = {2012}
}
@inproceedings{Oikonomidis2011a,
address = {University of Dundee, UK},
author = {Oikonomidis, I and Kyriazis, N and Argyros, A},
booktitle = {Proceedings of the 22nd British Machine Vision Conference, BMVC’2011},
month = aug,
file = {:C$\backslash$:/Users/d6ammt/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Oikonomidis, Kyriazis, Argyros - 2011 - Efficient model-based 3d tracking of hand articulations using kinect.pdf:pdf},
title = {{Efficient model-based 3d tracking of hand articulations using kinect}},
url = {http://www.ics.forth.gr/\_publications/2011\_09\_bmvc\_kinect\_hand\_tracking.pdf},
year = {2011},
pages={101.1--101.11}
}
@inproceedings{Oikonomidis2011b,
abstract = {Due to occlusions, the estimation of the full pose of a human hand interacting with an object is much more challenging than pose recovery of a hand observed in isolation. In this work we formulate an optimization problem whose solution is the 26-DOF hand pose together with the pose and model parameters of the manipulated object. Optimization seeks for the joint hand-object model that (a) best explains the incompleteness of observations resulting from occlusions due to hand-object interaction and (b) is physically plausible in the sense that the hand does not share the same physical space with the object. The proposed method is the first that solves efficiently the continuous, full-DOF, joint hand-object tracking problem based solely on markerless multicamera input. Additionally, it is the first to demonstrate how hand-object interaction can be exploited as a context that facilitates hand pose estimation, instead of being considered as a complicating factor. Extensive quantitative and qualitative experiments with simulated and real world image sequences as well as a comparative evaluation with a state-of-the-art method for pose estimation of isolated hands, support the above findings.},
author = {Oikonomidis, Iason and Kyriazis, Nikolaos and Argyros, Antonis A.},
booktitle = {2011 International Conference on Computer Vision},
doi = {10.1109/ICCV.2011.6126483},
file = {:C$\backslash$:/Users/d6ammt/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Oikonomidis, Kyriazis, Argyros - 2011 - Full DOF tracking of a hand interacting with an object by modeling occlusions and physical constraints.pdf:pdf},
isbn = {978-1-4577-1102-2},
month = nov,
pages = {2088--2095},
publisher = {IEEE},
title = {{Full DOF tracking of a hand interacting with an object by modeling occlusions and physical constraints}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6126483},
year = {2011}
}

@misc{Organisation2011,
author = {{OpenNI Organisation}},
booktitle = {IEEE Spectrum},
title = {{OpenNI \& NITE Libraries}},
howpublished  = {http://openni.org/},
note = {[Online; accessed 05-March-2013]},
urldate = {23/08/12},
year = {2011}
}
@inproceedings{Patsadu2012,
abstract = {In this paper, we propose a comparison of human gesture recognition using data mining classification methods in video streaming. In particular, we are interested in a specific stream of vector of twenty body-joint positions which are representative of the human body captured by Kinect camera. The recognized gesture patterns of the study are stand, sit down, and lie down. Classification methods chosen for comparison study are backpropagation neural network, support vector machine, decision tree, and naive Bayes. Experimental results have shown that the backpropagation neural network method outperforms other classification methods and can achieve recognition with 100\% accuracy. Moreover, the average accuracy of all classification methods used in this study is 93.72\%, which confirms the high potential of using the Kinect camera in human body recognition applications. Our future work will use the knowledge obtained from these classifiers in time series analysis of gesture sequence for detecting fall motion in a smart home system.},
author = {Patsadu, Orasa and Nukoolkit, Chakarida and Watanapa, Bunthit},
booktitle = {2012 Ninth International Conference on Computer Science and Software Engineering (JCSSE)},
month = may,
pages = {28--32},
publisher = {IEEE},
title = {{Human gesture recognition using Kinect camera}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6261920},
year = {2012}
}
@inproceedings{Rekimotoa,
abstract = {In this paper we introduce two input devices for wearable computers, called GestureWrist and GesturePad. Both devices allow users to interact with wearable or nearby computers by using gesture-based commands. Both are designed to be as unobtrusive as possible, so they can be used under various social contexts. The first device, called GestureWrist, is a wristband-type input device that recognizes hand gestures and forearm movements. Unlike DataGloves or other hand gesture-input devices, all sensing elements are embedded in a normal wristband. The second device, called GesturePad, is a sensing module that can be attached on the inside of clothes, and users can interact with this module from the outside. It transforms conventional clothes into an interactive device without changing their appearance},
author = {Rekimoto, J.},
booktitle = {Proceedings Fifth International Symposium on Wearable Computers},
doi = {10.1109/ISWC.2001.962092},
isbn = {0-7695-1318-2},
pages = {21--27},
publisher = {IEEE Comput. Soc},
title = {{GestureWrist and GesturePad: unobtrusive wearable interaction devices}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=962092}
}
@inproceedings{Robertson2012,
address = {New York, New York, USA},
author = {Robertson, Judy and Macvean, Andrew and Howland, Katy},
booktitle = {Proceedings of the 11th International Conference on Interaction Design and Children - IDC '12},
doi = {10.1145/2307096.2307100},
file = {:C$\backslash$:/Users/d6ammt/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Robertson, Macvean, Howland - 2012 - Embedding technology in the classroom.pdf:pdf},
isbn = {9781450310079},
keywords = {ecological validly,educational software,teacher training},
month = jun,
pages = {20},
publisher = {ACM Press},
title = {{Embedding technology in the classroom}},
url = {http://dl.acm.org/citation.cfm?id=2307096.2307100},
year = {2012}
}
@inproceedings{Satyavolu2012,
abstract = {This article presents an analysis of using multiple Microsoft Kinects to track users in a VR system. More specifically, we analyse the capability of Kinects to track infrared points for use in VR applications. Multiple Kinect sensors may serve as a low cost and affordable means to track position information across a large lab space in applications where precise location tracking is not necessary. We present our findings and analysis of the tracking range of a Kinect sensor in situations in which multiple Kinects are present. Overall, the Kinect sensor works well for this application and in lieu of more expensive options, the Kinect sensors may be a viable option for very low-cost tracking in VR applications.},
author = {Satyavolu, Srivishnu and Bruder, Gerd and Willemsen, Pete and Steinicke, Frank},
booktitle = {2012 IEEE Virtual Reality (VR)},
file = {:C$\backslash$:/Users/d6ammt/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Satyavolu et al. - 2012 - Analysis of IR-based virtual reality tracking using multiple Kinects.pdf:pdf},
month = mar,
pages = {149--150},
publisher = {IEEE},
title = {{Analysis of IR-based virtual reality tracking using multiple Kinects}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6180925},
year = {2012}
}
@article{Salvi2010,
abstract = {Shape reconstruction using coded structured light is considered one of the most reliable techniques to recover object surfaces. Having a calibrated projector–camera pair, a light pattern is projected onto the scene and imaged by the camera. Correspondences between projected and recovered patterns are found and used to extract 3D surface information. This paper presents an up-to-date review and a new classification of the existing techniques. Some of these techniques have been implemented and compared, obtaining both qualitative and quantitative results. The advantages and drawbacks of the different patterns and their potentials are discussed.},
author = {Salvi, Joaquim and Fernandez, Sergio and Pribanic, Tomislav and Llado, Xavier},
doi = {10.1016/j.patcog.2010.03.004},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {3d measuring devices,active stereo,coded patterns,computer vision,fourier transform profilometry,pattern projection,structured light},
month = aug,
number = {8},
pages = {2666--2680},
title = {{A state of the art in structured light patterns for surface profilometry}},
url = {http://dx.doi.org/10.1016/j.patcog.2010.03.004},
volume = {43},
year = {2010}
}

@techreport{Schroder2011,
author = {Schr\"{o}der, Y and Scholz, A and Berger, K},
booktitle = {Computer \ldots},
file = {:C$\backslash$:/Users/d6ammt/Documents/Mendeley Desktop/Schr\"{o}der, Scholz, Berger - 2011 - Multiple Kinect Studies.pdf:pdf},
institution = {TU Braunschweig},
title = {{Multiple Kinect Studies}},
url = {http://www.cg.cs.tu-bs.de/media/publications/multikinects\_1.pdf},
year = {2011}
}
@article{Schrum2008,
author = {Schrum, L and Shelley, G and Miller, R},
file = {:C$\backslash$:/Users/d6ammt/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schrum, Shelley, Miller - 2008 - Understanding tech-savvy teachers Identifying their characteristics, motivation, and challenges.pdf:pdf},
journal = {International Journal of Technology in Teaching and Learning},
number = {1},
pages = {1--20},
title = {{Understanding tech-savvy teachers: Identifying their characteristics, motivation, and challenges}},
url = {http://www.sicet.org/journals/ijttl/issue0801/4\_1\_1\_Schrum.pdf},
volume = {4},
year = {2008}
}
@article{Selwyn2010,
author = {Selwyn, N},
title = {{Schools and schooling in the digital age: A critical analysis}},
url = {http://books.google.co.uk/books?hl=en\&amp;lr=\&amp;id=eKVw7invWsMC\&amp;oi=fnd\&amp;pg=PP1\&amp;ots=b-6V6PN\_Zt\&amp;sig=uQdRGbU9g-1ZrMF0wkUMCypPlLg},
year = {2010}
}
@article{Selwyn2011,
author = {Selwyn, N},
title = {{Education and technology: key issues and debates}},
url = {http://books.google.co.uk/books?hl=en\&amp;lr=\&amp;id=SFYeie9rPdsC\&amp;oi=fnd\&amp;pg=PP2\&amp;ots=yK5yQ7gXSr\&amp;sig=opvPiIxCXMGBtCg32QdylDljCK8},
year = {2011}
}
@article{Shirley2010,
author = {Shirley, Melissa L. and Irving, Karen E. and Sanalan, Vehbi A. and Pape, Stephen J. and Owens, Douglas T.},
issn = {1571-0068},
journal = {International Journal of Science and Mathematics Education},
month = oct,
number = {2},
pages = {459--481},
title = {{The Practicality of Implementing Connected Classroom Technology in Secondary Mathematics and Science Classrooms}},
url = {http://www.springerlink.com/content/21875l0582811840/},
volume = {9},
year = {2010}
}
@article{Stone2011,
abstract = {We present an investigation of a new, inexpensive depth camera device, the Microsoft Kinect, for passive fall risk assessment in home environments. In order to allow older adults to safely continue living in independent settings as they age, the ability to assess their risk of falling, along with detecting the early onset of illness and functional decline, is essential. Daily measurements of temporal and spatial gait parameters would greatly facilitate such an assessment. Ideally, these measurements would be obtained passively, in normal daily activity, without the need for wearable devices or expensive equipment. In this work, we evaluate the use of the inexpensive Microsoft Kinect for obtaining measurements of temporal and spatial gait parameters as compared to an existing web-camera based system, along with a Vicon motion capture system for ground truth. We describe our techniques for extracting gait parameters from the Kinect data, as well as the advantages of the Kinect over the web-camera based system for passive, in-home fall risk assessment.},
author = {Stone, E.E. and Skubic, M.},
file = {:C$\backslash$:/Users/d6ammt/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Stone, Skubic - 2011 - Evaluation of an inexpensive depth camera for passive in-home fall risk assessment.pdf:pdf},
journal = {Journal of Ambient Intelligence and Smart Environments},
number = {4},
pages = {349--361},
title = {{Evaluation of an inexpensive depth camera for passive in-home fall risk assessment}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6038771},
volume = {3},
year = {2011}
}
@article{Varona2009,
abstract = {In most of the existing human–computer interfaces, enactive knowledge as new natural interaction paradigm has not been fully exploited yet. Recent technological advances have created the possibility to enhance naturally and significantly the interface perception by means of visual inputs, the so-called Vision-Based Interfaces (VBI). In the present paper, we explore the recovery of the user’s body posture by means of combining robust computer vision techniques and a well known inverse kinematics algorithm in real-time. Specifically, we focus on recognizing the user’s motions with a particular mean, that is, a bodygesture. Defining an appropriate representation of the user’s body posture based on a temporal parameterization, we apply non-parametric techniques to learn and recognize the user’s bodygestures. This scheme of recognition has been applied to control a computer videogame in real-time to show the viability of the presented approach.},
author = {Varona, Javier and Jaume-i-Cap\'{o}, Antoni and Gonz\`{a}lez, Jordi and Perales, Francisco J.},
issn = {09535438},
journal = {Interacting with Computers},
keywords = {enactive interfaces,human–computer interaction,vision-based interfaces},
month = jan,
number = {1-2},
pages = {3--10},
title = {{Toward natural interaction through visual recognition of body gestures in real-time}},
url = {http://dx.doi.org/10.1016/j.intcom.2008.10.001},
volume = {21},
year = {2009}
}
@article{Wachs2011,
author = {Wachs, Juan Pablo and K\"{o}lsch, Mathias and Stern, Helman and Edan, Yael},
doi = {10.1145/1897816.1897838},
file = {:C$\backslash$:/Users/d6ammt/Documents/Mendeley Desktop//Wachs et al. - 2011 - Vision-based hand-gesture applications.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = feb,
number = {2},
pages = {60},
title = {{Vision-based hand-gesture applications}},
url = {http://dl.acm.org/ft\_gateway.cfm?id=1897838\&type=html},
volume = {54},
year = {2011}
}
@inproceedings{Wang2008,
abstract = {Multimedia information terminals have been rapidly developed in recent years, which is a global trend. This paper will introduce the psychological cognitive problems in the design of interactive design in the multimedia information terminals, put forward the phenomenon of metaphor in the interactive design, and develop the method of interaction design through considering the metaphor understanding of users.},
author = {Wang, Xiaochun},
booktitle = {2008 9th International Conference on Computer-Aided Industrial Design and Conceptual Design},
doi = {10.1109/CAIDCD.2008.4730568},
file = {:C$\backslash$:/Users/d6ammt/Documents/Mendeley Desktop//Wang - 2008 - Metaphor of interaction design in multimedia information terminals design.pdf:pdf},
isbn = {978-1-4244-3290-5},
month = nov,
pages = {268--270},
publisher = {IEEE},
title = {{Metaphor of interaction design in multimedia information terminals design}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=4730568},
year = {2008}
}

@inproceedings{Wang2012,
address = {Kyoto, Japan},
author = {Wang, J and Zhang, C and Zhu, W and Zhang, Z and Xiong, Z and Chou, P},
booktitle = {International Conference on Acoustics, Speech, and Signal Processing},
file = {:C$\backslash$:/Users/d6ammt/Documents/Mendeley Desktop/Wang et al. - 2012 - 3D Scene Reconstruction by Multiple Structured-Light Based Commodity Depth Cameras.pdf:pdf},
publisher = {IEEE},
title = {{3D Scene Reconstruction by Multiple Structured-Light Based Commodity Depth Cameras}},
url = {http://research.microsoft.com/pubs/158080/paper-phil-Cha-ZZ-final.pdf},
year = {2012}
}
@inproceedings{Wilson2007a,
abstract = {Recently developed depth-sensing video camera technologies provide precise per-pixel range data in addition to color video. Such cameras will find application in robotics and vision-based human computer interaction scenarios such as games and gesture input systems. We present an interactive tabletop system which uses a depth-sensing camera to build a height map of the objects on the table surface. This height map is used in a driving simulation game that allows players to drive a virtual car over real objects placed on the table. Players can use folded bits of paper, for example, to lay out a course of ramps and other obstacles. A projector displays the position of the car on the surface, such that when the car is driven over a ramp, for example, it jumps appropriately. A second display shows a synthetic graphical view of the entire surface, or a traditional arcade view from behind the car. Micromotorcross is a fun initial investigation into the applicability of depth-sensing cameras to tabletop interfaces. We present details on its implementation, and speculate on how this technology will enable new tabletop interactions.},
author = {Wilson, Andrew D.},
booktitle = {Second Annual IEEE International Workshop on Horizontal Interactive Human-Computer Systems (TABLETOP'07)},
doi = {10.1109/TABLETOP.2007.35},
isbn = {0-7695-3013-3},
month = oct,
pages = {201--204},
publisher = {IEEE},
title = {{Depth-Sensing Video Cameras for 3D Tangible Tabletop Interaction}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4384131},
year = {2007}
}
@inproceedings{Wilson2010,
address = {New York, New York, USA},
author = {Wilson, Andrew D. and Benko, Hrvoje},
booktitle = {Proceedings of the 23nd annual ACM symposium on User interface software and technology - UIST '10},
doi = {10.1145/1866029.1866073},
file = {:C$\backslash$:/Users/d6ammt/Documents/Mendeley Desktop//Wilson, Benko - 2010 - Combining multiple depth cameras and projectors for interactions on, above and between surfaces.pdf:pdf},
isbn = {9781450302715},
keywords = {augmented reality,depth cameras,interactive spaces,surface computing,ubiquitous computing},
month = oct,
pages = {273},
publisher = {ACM Press},
title = {{Combining multiple depth cameras and projectors for interactions on, above and between surfaces}},
url = {http://dl.acm.org/citation.cfm?id=1866029.1866073},
year = {2010}
}
@inproceedings{Winkler2012,
abstract = {Today, talks, presentations, and lectures are often captured on video to give a broad audience the possibility to (re-)access the content. As presenters are often moving around during a talk it is necessary to guide recording cameras. We present an automatic solution for user tracking and camera control. It uses a depth camera for user tracking, and a scalable networking architecture based on publish/subscribe messaging for controlling multiple video cameras. Furthermore, we present our experiences with the system during actual lectures at an university.},
author = {Winkler, Michael Bjorn and Hover, Kai Michael and Hadjakos, Aristotelis and Muhlhauser, Max},
booktitle = {2012 IEEE International Symposium on Multimedia},
doi = {10.1109/ISM.2012.96},
isbn = {978-1-4673-4370-1},
month = dec,
pages = {471--476},
publisher = {IEEE},
title = {{Automatic Camera Control for Tracking a Presenter during a Talk}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6424709},
year = {2012}
}
@article{Zhu2011,
abstract = {In this paper, we address natural human-robot interaction (HRI) in a smart assisted living (SAIL) system for the elderly and the disabled. Two common HRI problems are studied: hand gesture recognition and daily activity recognition. For hand gesture recognition, we implemented a neural network for gesture spotting and a hierarchical hidden Markov model for context-based recognition. For daily activity recognition, a multisensor fusion scheme is developed to process motion data collected from the foot and the waist of a human subject. Experiments using a prototype wearable sensor system show the effectiveness and accuracy of our algorithms.},
author = {Zhu, Chun and Sheng, Weihua},
doi = {10.1109/TSMCA.2010.2093883},
issn = {1083-4427},
journal = {IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},
month = may,
number = {3},
pages = {569--573},
title = {{Wearable Sensor-Based Hand Gesture and Daily Activity Recognition for Robot-Assisted Living}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=\&arnumber=5682421\&contentType=Journals+\%26+Magazines\&searchField\%3DSearch\_All\%26queryText\%3DWearable+Sensor-Based+Hand+Gesture+and+Daily+Activity+...},
volume = {41},
year = {2011}
}